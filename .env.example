# ============================================================
# CAISOGAMES V2 Environment Variables
# ============================================================
# Copy this file to .env and fill in your values

# =============================================================================
# Gemini API Configuration (Phase 1+)
# =============================================================================

# Vercel API Proxy URL (Production)
# This is the URL of your deployed Vercel function that proxies Gemini API calls
# Example: https://your-project.vercel.app
# The actual endpoint will be: https://your-project.vercel.app/api/gemini/generate
VERCEL_PROXY_URL=https://caisogames2.vercel.app

# For local development with Vercel CLI:
# 1. Run: vercel dev
# 2. Uncomment the line below:
# VERCEL_PROXY_URL=http://localhost:3000

# IMPORTANT: GEMINI_API_KEY should be set in Vercel dashboard, NOT here
# How to set GEMINI_API_KEY in Vercel:
# 1. Go to https://vercel.com/your-project/settings/environment-variables
# 2. Add GEMINI_API_KEY with your API key from https://aistudio.google.com/app/apikey
# 3. Select all environments (Production, Preview, Development)
# 4. Redeploy

# =============================================================================
# Development Configuration
# =============================================================================

# Mock Mode (Development Only)
# Set to "true" to use mock LLM responses for testing without API calls
# Set to "false" to use real Gemini API (requires GEMINI_API_KEY in Vercel)
# NOTE: Currently enabled in agents/shared/llm.py:51 for Phase 1 testing
MOCK_MODE=true

# Output Directory
# Where generated game files will be saved
OUTPUT_DIR=./output

# =============================================================================
# Agent Configuration
# =============================================================================

# Default AI Model
# Options: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp
DEFAULT_MODEL=gemini-1.5-flash

# Temperature for AI generation (0.0 - 1.0)
# Lower = more deterministic, Higher = more creative
AI_TEMPERATURE=0.7

# Max tokens for AI responses
MAX_TOKENS=8000

# Quality Gate Thresholds (0-100)
QUALITY_GATE_DESIGN=90
QUALITY_GATE_CODE=80

# =============================================================================
# Game Engine Configuration (@caisogames/ai-engine)
# =============================================================================

# Default canvas size for generated games
DEFAULT_CANVAS_WIDTH=800
DEFAULT_CANVAS_HEIGHT=600

# Default target FPS
DEFAULT_TARGET_FPS=60

# Default gravity (pixels/second^2)
DEFAULT_GRAVITY=980

# =============================================================================
# Audio Generation API (Phase 2)
# =============================================================================

# These will be configured in Phase 2 after API selection
# SUNO_API_KEY=your_suno_api_key_here
# ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# =============================================================================
# General Settings
# =============================================================================

# Environment
NODE_ENV=development

# Logging level (debug, info, warn, error)
LOG_LEVEL=info

# Claude Code Agent Teams
# NOTE: Already configured in .claude/settings.local.json
# CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1

# =============================================================================
# Phase 1 Development Notes
# =============================================================================

# Local Development Workflow:
# 1. Set MOCK_MODE=true (or keep llm.py:51 as self.mock_mode = True)
# 2. Run: python3 agents/project_manager/pm_agent.py "your game idea"
# 3. Check output in ./output/game-{timestamp}/ directory
# 4. Review: concept.json, levels.json, narrative.json, project_context.json

# Production Workflow (when ready):
# 1. Deploy to Vercel with GEMINI_API_KEY set in dashboard
# 2. Change llm.py:51 to self.mock_mode = False (or read from env)
# 3. Set VERCEL_PROXY_URL to your Vercel deployment URL
# 4. Agents will call Gemini API securely through Vercel proxy

# Security Best Practices:
# - NEVER commit .env to git (already in .gitignore)
# - NEVER hardcode API keys in source code
# - Always use Vercel environment variables for production secrets
# - Use MOCK_MODE for local development without API keys
